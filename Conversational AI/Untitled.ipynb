{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3a39d8c",
   "metadata": {},
   "source": [
    "Feed-Forward Neural Network(ANN) : Used for general Regression and Classification problems.\n",
    "\n",
    "Convolution Neural Network(CNN) : Used for object detection and image classification.\n",
    "\n",
    "Deep Belief Network : Used in healthcare sectors for cancer detection.\n",
    "\n",
    "Recurrent Neural Network(RNN) : Used for speech recognition, voice recognition , time series prediction, machine translation and natural language processing\n",
    "\n",
    "when processing of one part is dependent of another which means output is not dependent on prior information then we use RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc1365",
   "metadata": {},
   "source": [
    "Types of RNN:\n",
    "one to one : single input & single output, it is a vanilla neural network\n",
    "\n",
    "one to many : single input & multiple output, eg: image caption\n",
    "\n",
    "many to one :many input & single output\n",
    "\n",
    "many to many : muliple input & multiple output eg: macine translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05e7703",
   "metadata": {},
   "source": [
    "We should process the data, handle missing values outliers. The input should be normalized"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75909e30",
   "metadata": {},
   "source": [
    "Hidden state stores information about all the previous inputs in a weighted manner. Most recent inputs gets higher value and older inputs get lower values. The hidden state of the previous time step gets concatenated with the input of the current time step and is fed into tanh activation. the tanh activation scales all the values between -1 to 1 and this becomes the hidden state of the current time step. Based on the types of RNN if we want to predict output at each step , this hidden state is fed into a softmax layer and we get the output for the current time step. The current hidden state becomes the input to the RNN block of te next time step. This process goes on untill the end of the sentence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af17a690",
   "metadata": {},
   "source": [
    "Now we have a prediction at each step. We compare it with actual labels and compute the loss for each time step. this concludes a single forward propagation step in an RNN.\n",
    "\n",
    "The back propagation of an RNN occurs in the exact reverse manner of forwarding propagation\n",
    "\n",
    "RNN suffers from from short-term memory. If a sequence is long enough, they'll have a hard time carrying information from earlier time steps to later onces. So if you are trying to process a paragraph of text to do predictions. RNN may leave out important information from beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a992e72",
   "metadata": {},
   "source": [
    "Vanishing Gadient problem : \n",
    "\n",
    "Exploring Gadient problem : while tarining a neural network, if the slope tends to grow exponentially instead of decaying\n",
    "\n",
    "Grdient solution : Long Short-Term Memory Networks (LSTMs)\n",
    "\n",
    "LSTMs steps: \n",
    "1. Decide how much past data is useful\n",
    "2. Determines how many units to be added\n",
    "3. Decide what to be presented as output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "573f8024",
   "metadata": {},
   "source": [
    "\" Get the data online \"\\\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/irish-lyrics-eof.txt \\\n",
    "    -O /tmp/irish-lyrics-eof.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8d304b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58a52b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('irish-lyrics-eof.txt', \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaedf75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=data.lower().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac9cac7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1692"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8823af88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7a3a5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences=corpus[:1500]\n",
    "test_sentences=corpus[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c5dce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(num_words=1000,oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index=tokenizer.word_index\n",
    "\n",
    "train_sequence=tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded=pad_sequences(train_sequence,maxlen=100,padding='pre')\n",
    "\n",
    "test_sequence=tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded=pad_sequences(test_sequence,maxlen=100,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c59b244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_padded),type(test_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0683fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          64000     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               66048     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 138,369\n",
      "Trainable params: 138,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(1000,64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')    \n",
    "]) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7d56b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39953a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(train_padded,train_labels,epochs=30,validation_data=(test_padded,test_labels),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377638ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=\n",
    "Y = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b3f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def histogram(string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string])\n",
    "    plt.title(string)\n",
    "    plt.ylabel(string)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train','test'],loc='upper left')\n",
    "    plt.show()\n",
    "histogram('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91b22f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbaff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [\"granny starting to fear spiders in the garden might be real\", \"game of thrones season finale showing this sunday night\"]\n",
    "sequences = tokenizer.texts_to_sequences(sentence)\n",
    "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "print(model.predict(padded))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
