{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaf6ff36",
   "metadata": {},
   "source": [
    "# Text cleaning\n",
    "syntax : result = re.sub(pattern, repl, string, count=0, flags=0);\n",
    "\\\n",
    "result = re.sub('abc',  '',    input)           # Delete pattern abc\n",
    "\\\n",
    "result = re.sub('abc',  'def', input)           # Replace pattern abc -> def\n",
    "\\\n",
    "result = re.sub(r'\\s+', ' ',   input)           # Eliminate duplicate whitespaces using wildcards\n",
    "\\\n",
    "result = re.sub('abc(def)ghi', r'\\1', input)    # Replace a string with a part of itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fd5d121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' NLP is an intresting field. '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# regular expressions\n",
    "doc=\" NLP  is    an        intresting           field.    \"\n",
    "# removing extra spaces\n",
    "new_doc=re.sub(\"\\s+\",\" \",doc)\n",
    "new_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a00747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello ! How are you ? please to meet you all !!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello   How are you   please to meet you all   '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove punctuations( # . @ $ % ^ & , . ; : )\n",
    "string=\"Hello ! How are you ? please to meet you all !!\"\n",
    "print(string)\n",
    "re.sub(\"[^0-9A-Za-z]\",\" \",string)\n",
    "#re.sub(\"[^\\w\\s]\",\"\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c424cd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HElLo AlL It iS RAjIYa\n",
      "hello all it is rajiya\n",
      "HELLO ALL IT IS RAJIYA\n"
     ]
    }
   ],
   "source": [
    "# case normalization\n",
    "s=\"HElLo AlL It iS RAjIYa\"\n",
    "print(s)\n",
    "print(s.lower())\n",
    "print(s.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea4e14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rproddatur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Hello', 'How', 'are', 'you', 'please', 'to', 'meet', 'you', 'all']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenization -> word_tokenize()\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "text=\"Hello ! How are you ? please to meet you all !!\"\n",
    "text=re.sub(\"[^0-9A-Za-z]\",\" \",text)\n",
    "text=nltk.tokenize.word_tokenize(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99fe16ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rproddatur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello How please meet'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stopwords=stopwords.words('english')\n",
    "words=\" \".join([i for i in text if i not in stopwords])\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9272b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'how', 'pleas', 'meet']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stemming -> finding the root word\n",
    "stemmer=nltk.PorterStemmer()\n",
    "words= nltk.word_tokenize(words)\n",
    "w = [stemmer.stem(i) for i in words]\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3acce548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it', 'bother', 'work', 'overnight']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = nltk.PorterStemmer()\n",
    "text_2 =  'Its bothering working overnight'\n",
    "text_2 = nltk.word_tokenize(text_2)\n",
    "w = [stemmer.stem(i) for i in text_2]\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d463c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
