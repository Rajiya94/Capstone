{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using py spark in vm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing find spark and pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/local/spark')\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now start SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"Python Spark SQL example\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataFrame from data source -csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerDF=spark.read.load(\"/home/hduser/Downloads/sharedfolder/Customer.txt\",format=\"csv\",sep=\"\\t\",interSchema=\"true\",header='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data transdormation (displaying data in different ways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- customer_name: string (nullable = true)\n",
      " |-- customer_city: string (nullable = true)\n",
      " |-- customer_state: string (nullable = true)\n",
      " |-- customer_zipcode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customerDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|   customer_name|\n",
      "+----------------+\n",
      "|     Mary Torres|\n",
      "|      Jose Haley|\n",
      "|      Mary Smith|\n",
      "|  Richard Maddox|\n",
      "|  Margaret Booth|\n",
      "|  Mary Henderson|\n",
      "|     Lisa Walker|\n",
      "|   Jonathan Hill|\n",
      "|Carolyn Sheppard|\n",
      "|    Mary Mendoza|\n",
      "|   Michael Smith|\n",
      "|    James Holmes|\n",
      "|     Mary Dawson|\n",
      "|    Adam Marquez|\n",
      "|    Gloria Smith|\n",
      "|       Mary Webb|\n",
      "|  Nancy Alvarado|\n",
      "|  Russell Flores|\n",
      "|    Denise Smith|\n",
      "|  Jose Dickerson|\n",
      "+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customerDF.select(\"customer_name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+\n",
      "|   customer_name|customer_city|\n",
      "+----------------+-------------+\n",
      "|     Mary Torres|       Caguas|\n",
      "|      Jose Haley|     Columbus|\n",
      "|      Mary Smith|      Houston|\n",
      "|  Richard Maddox|       Caguas|\n",
      "|  Margaret Booth|    Arlington|\n",
      "|  Mary Henderson|       Caguas|\n",
      "|     Lisa Walker|       Caguas|\n",
      "|   Jonathan Hill|      Phoenix|\n",
      "|Carolyn Sheppard|Pompano Beach|\n",
      "|    Mary Mendoza|       Caguas|\n",
      "|   Michael Smith|       Caguas|\n",
      "|    James Holmes|     Hilliard|\n",
      "|     Mary Dawson|       Caguas|\n",
      "|    Adam Marquez|  San Antonio|\n",
      "|    Gloria Smith|       Caguas|\n",
      "|       Mary Webb|   San Marcos|\n",
      "|  Nancy Alvarado|     Flushing|\n",
      "|  Russell Flores|       Caguas|\n",
      "|    Denise Smith|    Rego Park|\n",
      "|  Jose Dickerson|         Mesa|\n",
      "+----------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customerDF.select(customerDF[\"customer_name\"],customerDF['customer_city']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+---------------+--------------+----------------+\n",
      "|customer_id|   customer_name|  customer_city|customer_state|customer_zipcode|\n",
      "+-----------+----------------+---------------+--------------+----------------+\n",
      "|       5577|      Mary Smith|        Modesto|            CA|           95350|\n",
      "|       1745|      Mary Smith|Rowland Heights|            CA|           91748|\n",
      "|      11444|Kathleen Patrick|      San Diego|            CA|           92109|\n",
      "|       8846|    Thomas Smith|          Indio|            CA|           92201|\n",
      "|       6237|  Bobby Anderson|       El Cajon|            CA|           92020|\n",
      "|       4085|       Mary Carr|  Panorama City|            CA|           91402|\n",
      "|       8705|  Patricia Smith|       Stockton|            CA|           95207|\n",
      "|       3669|       Mary Soto| San Bernardino|            CA|           92410|\n",
      "|       6101|      Mary Smith|    Los Angeles|            CA|           90033|\n",
      "|      11697|  Jessica Thomas|  Laguna Niguel|            CA|           92677|\n",
      "|       1295|   Theresa Lopez|       Winnetka|            CA|           91306|\n",
      "|       4814|     Paul Suarez|    Simi Valley|            CA|           93065|\n",
      "|       8530|   William Smith|       Highland|            CA|           92346|\n",
      "|       3846|    Ronald Lewis|        Ontario|            CA|           91764|\n",
      "|      10476|     John Hodges|       Cerritos|            CA|           90703|\n",
      "|      10243|  Donna Anderson|    Los Angeles|            CA|           90034|\n",
      "|      11595|   Zachary Jones|        Modesto|            CA|           95355|\n",
      "|        847|  Jerry Ferguson|      San Diego|            CA|           92102|\n",
      "|       3440|    Mary Edwards|        Salinas|            CA|           93905|\n",
      "|       3400|     Frank Lewis|  Moreno Valley|            CA|           92557|\n",
      "+-----------+----------------+---------------+--------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customerDF.filter(customerDF[\"customer_state\"] == 'CA').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|customer_state|count|\n",
      "+--------------+-----+\n",
      "|            AZ|   19|\n",
      "|            SC|    2|\n",
      "|            LA|    7|\n",
      "|            MN|    1|\n",
      "|            NJ|   19|\n",
      "|            DC|    4|\n",
      "|            OR|    4|\n",
      "|            VA|   14|\n",
      "|            RI|    2|\n",
      "|            KY|    1|\n",
      "|            MI|   28|\n",
      "|            NV|   16|\n",
      "|            WI|    9|\n",
      "|            ID|    2|\n",
      "|            CA|  187|\n",
      "|            CT|    8|\n",
      "|            NC|   19|\n",
      "|            MD|   19|\n",
      "|            DE|    1|\n",
      "|            MO|   13|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customerDF.groupby(\"customer_state\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create temp view for running SQL queries on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerDF.createOrReplaceTempView(\"customers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL can be run on DataFrame that are registered as temp view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+\n",
      "|customer_state|state_count|\n",
      "+--------------+-----------+\n",
      "|            CA|        187|\n",
      "|            NY|         79|\n",
      "|            TX|         62|\n",
      "|            PR|        505|\n",
      "+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT customer_state, count(*) as state_count FROM customers GROUP BY customer_state HAVING state_count>=50\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we should store the query output in different variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cstateCount50 = spark.sql(\"SELECT customer_state, count(*) as state_count FROM customers GROUP BY customer_state HAVING state_count>=50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cstateCount50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+\n",
      "|customer_state|state_count|\n",
      "+--------------+-----------+\n",
      "|            CA|        187|\n",
      "|            NY|         79|\n",
      "|            TX|         62|\n",
      "|            PR|        505|\n",
      "+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cstateCount50.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_state: string (nullable = true)\n",
      " |-- state_count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cstateCount50.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cstateCount50.coalesce(1).write.parquet(\"cStateOutput1.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is small we can coalesce all the partition into one column ans write it into cStateOutput1.parquet file, for large datasets it is expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively the following syntax is also allowed.\n",
    "we can use the parquet synatx since it is the default dormat used by sparksql\n",
    "\n",
    "cstateCount50.coalesce(1).write.save(\"cStateOutput1.parquet\",format='parquet')\n",
    "\n",
    "cstateCount50.coalesce(1).write.save(\"cStateOutput1.parquet\")\n",
    "\n",
    "cstateCount50.coalesce(1).write.save(\"cStateOutput1.json\",format=\"json\")\n",
    "\n",
    "cstateCount50.coalesce(1).write.json(\"cStateOutput1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cstateCount50.coalesce(1).write.json(\"cStateOutput1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "readingPQ=spark.read.parquet('cStateOutput1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+\n",
      "|customer_state|state_count|\n",
      "+--------------+-----------+\n",
      "|            CA|        187|\n",
      "|            NY|         79|\n",
      "|            TX|         62|\n",
      "|            PR|        505|\n",
      "+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "readingPQ.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create dataFrame from datasource -json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "productDF = spark.read.load(\"/home/hduser/Downloads/sharedfolder/products.json\", format = 'json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- category_id: long (nullable = true)\n",
      " |-- customer_id: long (nullable = true)\n",
      " |-- product_category: string (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- product_price: double (nullable = true)\n",
      " |-- product_quantity: long (nullable = true)\n",
      " |-- salestxn_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "productDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|        product_name|product_price|\n",
      "+--------------------+-------------+\n",
      "|O'Brien Men's Neo...|        49.98|\n",
      "|O'Brien Men's Neo...|        49.98|\n",
      "|Under Armour Wome...|        31.99|\n",
      "|O'Brien Men's Neo...|        49.98|\n",
      "|Pelican Sunstream...|       199.99|\n",
      "|Nike Men's CJ Eli...|       129.99|\n",
      "|Diamondback Women...|       299.98|\n",
      "|Field & Stream Sp...|       399.98|\n",
      "|Perfect Fitness P...|        59.99|\n",
      "|Nike Men's CJ Eli...|       129.99|\n",
      "|Pelican Sunstream...|       199.99|\n",
      "|Nike Men's CJ Eli...|       129.99|\n",
      "|Diamondback Women...|       299.98|\n",
      "|Nike Men's CJ Eli...|       129.99|\n",
      "|Nike Men's Dri-FI...|         50.0|\n",
      "|O'Brien Men's Neo...|        49.98|\n",
      "|O'Brien Men's Neo...|        49.98|\n",
      "|Nike Men's Dri-FI...|         50.0|\n",
      "|Diamondback Women...|       299.98|\n",
      "|Under Armour Girl...|        39.99|\n",
      "+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "productDF.select(productDF[\"product_name\"], productDF['product_price']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|   product_category|count|\n",
      "+-------------------+-----+\n",
      "|  Training by Sport|    5|\n",
      "|   Men's Golf Clubs|   21|\n",
      "|   Camping & Hiking|   44|\n",
      "|Fitness Accessories|   47|\n",
      "|         Golf Shoes|    6|\n",
      "|         Basketball|   36|\n",
      "|        Electronics|   48|\n",
      "|          Team Shop|  162|\n",
      "|      Men's Apparel| 2085|\n",
      "|  Bike & Skate Shop| 1377|\n",
      "|  Golf Bags & Carts|   89|\n",
      "|    As Seen on  TV!| 2399|\n",
      "|       Boxing & MMA|  115|\n",
      "| Hunting & Shooting| 1785|\n",
      "|Baseball & Softball|    4|\n",
      "|       Golf Apparel|   51|\n",
      "| Women's Golf Clubs|   57|\n",
      "|      Shop By Sport|   26|\n",
      "|            Fishing| 1953|\n",
      "|        Accessories|  110|\n",
      "+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "productDF.groupby('product_category').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
